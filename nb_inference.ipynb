{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f133549e-49a7-44a0-b444-f374ea7df62b",
   "metadata": {},
   "source": [
    "# Inference base Phi-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd57c959-07d1-4c0f-b730-86f7bf454936",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 2/2 [00:01<00:00,  1.54it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"microsoft/phi-2\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "37acf578-0205-4efb-bfb7-25ac980804c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A bird is built without me. I have to be broken to let water out. What am I?\n",
      "Answer: A teacup. If you need more information, please ask a short question at the end of this answer. For example, \"What material are teacups made from?\"<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"A bird is built without me. I have to be broken to let water out. What am I?\"\n",
    "\n",
    "input_tokens = tokenizer(prompt, return_tensors=\"pt\").to(\"cuda\")\n",
    "output_tokens = model.generate(**input_tokens)\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11380acc-a271-407c-b3ed-eef5c36df6ca",
   "metadata": {},
   "source": [
    "# Inference fine-tuned Phi-2 (ChatML prompt format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a17f078a-2928-4702-b719-587aadcc789b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|█████████████████████████████████████████████████████████████████████████████| 2/2 [00:00<00:00,  2.07it/s]\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "modelpath=\"nikad/phi-2_riddles-evolved\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    modelpath,    \n",
    "    torch_dtype=torch.bfloat16,\n",
    "    device_map=\"auto\",\n",
    "    trust_remote_code=True,\n",
    "    # attn_implementation=\"flash_attention_2\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(modelpath) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69e14065-bb00-41c0-8745-4da3e92adccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|im_start|>user\n",
      "A bird is built without me. I have to be broken to let water out. What am I<|im_end|>\n",
      "<|im_start|>assistant\n",
      "The answer to the riddle is a \"glass.\" A glass is made by melting sand and other materials together, then cooling it down so that it becomes solid again. The process of making a glass involves breaking apart the raw materials in order to shape them into something new. Glass can also be described as being transparent or translucent because light passes through it easily. If you need further clarification on any aspect of this answer, please ask!<|im_end|>\n"
     ]
    }
   ],
   "source": [
    "question = \"A bird is built without me. I have to be broken to let water out. What am I\"\n",
    "messages = [\n",
    "    {\"role\": \"user\", \"content\": question},\n",
    "]\n",
    "        \n",
    "input_tokens = tokenizer.apply_chat_template(\n",
    "    messages, \n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\"\n",
    ").to(\"cuda\")\n",
    "output_tokens = model.generate(input_tokens, max_new_tokens=200)\n",
    "output = tokenizer.decode(output_tokens[0])\n",
    "\n",
    "print(output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
